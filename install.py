#!/usr/bin/env python3
"""
Script de instalaciÃ³n y configuraciÃ³n automÃ¡tica
Ollama MCP Server - Sistema completo de IA para desarrollo
"""

import os
import subprocess
import sys
from pathlib import Path

def print_header():
    print("ğŸš€" + "="*60 + "ğŸš€")
    print("   OLLAMA MCP SERVER - INSTALACIÃ“N AUTOMÃTICA")
    print("   Sistema integrado de IA para desarrollo")
    print("ğŸš€" + "="*60 + "ğŸš€\n")

def check_ollama():
    """Verificar si Ollama estÃ¡ instalado y funcionando"""
    try:
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… Ollama estÃ¡ instalado y funcionando")
            return True
        else:
            print("âŒ Ollama no estÃ¡ funcionando correctamente")
            return False
    except FileNotFoundError:
        print("âŒ Ollama no estÃ¡ instalado")
        print("   Instala desde: https://ollama.ai/")
        return False

def setup_venv():
    """Configurar entorno virtual"""
    venv_path = Path(".venv")
    
    if not venv_path.exists():
        print("ğŸ“¦ Creando entorno virtual...")
        subprocess.run([sys.executable, "-m", "venv", ".venv"])
        print("âœ… Entorno virtual creado")
    else:
        print("âœ… Entorno virtual ya existe")
    
    return venv_path

def install_dependencies(venv_path):
    """Instalar dependencias"""
    pip_path = venv_path / "bin" / "pip"
    
    if not pip_path.exists():
        pip_path = venv_path / "Scripts" / "pip.exe"  # Windows
    
    if pip_path.exists():
        print("ğŸ“š Instalando dependencias...")
        subprocess.run([str(pip_path), "install", "-r", "requirements.txt"])
        print("âœ… Dependencias instaladas")
    else:
        print("âŒ No se encontrÃ³ pip en el entorno virtual")

def setup_env_file():
    """Configurar archivo .env"""
    env_path = Path(".env")
    
    if not env_path.exists():
        print("âš™ï¸ Configurando archivo .env...")
        env_content = """# Ollama MCP Server Configuration

# GitHub Personal Access Token
# Get from: https://github.com/settings/tokens
# Required scopes: repo, public_repo, read:org
GITHUB_TOKEN=your_github_token_here

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
DEFAULT_MODEL=llama3.1:8b
CODING_MODEL=deepseek-coder:6.7b

# Server Configuration
SERVER_HOST=localhost
SERVER_PORT=8000
"""
        env_path.write_text(env_content)
        print("âœ… Archivo .env creado")
        print("ğŸ“ IMPORTANTE: Edita .env con tu GitHub token")
    else:
        print("âœ… Archivo .env ya existe")

def install_models():
    """Instalar modelos recomendados de Ollama"""
    models = [
        ("llama3.1:8b", "Chat general"),
        ("deepseek-coder:6.7b", "Asistencia de cÃ³digo"),
        ("qwen2.5-coder:7b", "CÃ³digo alternativo")
    ]
    
    print("ğŸ¤– Verificando modelos de Ollama...")
    
    for model, description in models:
        print(f"ğŸ“¥ Instalando {model} ({description})...")
        result = subprocess.run(['ollama', 'pull', model], capture_output=True)
        if result.returncode == 0:
            print(f"âœ… {model} instalado")
        else:
            print(f"âš ï¸ Error instalando {model} (opcional)")

def create_aliases():
    """Crear aliases para ~/.bashrc"""
    mcp_path = os.path.abspath(".")
    python_path = os.path.join(mcp_path, ".venv/bin/python")
    server_path = os.path.join(mcp_path, "ollama_mcp_server.py")
    
    aliases = f"""
# ======================================
# OLLAMA MCP SERVER - ALIASES OPTIMIZADOS
# ======================================

# FunciÃ³n principal MCP
mcp() {{
    case "$1" in
        start|server)
            cd {mcp_path} && {python_path} {server_path}
            ;;
        install|setup)
            cd {mcp_path} && {python_path} install.py
            ;;
        models)
            ollama list
            ;;
        pull)
            if [ -z "$2" ]; then
                echo "Uso: mcp pull <modelo>"
                echo "Ejemplos: mcp pull deepseek-coder:6.7b"
            else
                ollama pull "$2"
            fi
            ;;
        help|*)
            echo "ğŸ¤– Ollama MCP Server"
            echo "Comandos disponibles:"
            echo "  mcp start    - Iniciar servidor MCP"
            echo "  mcp models   - Ver modelos instalados"
            echo "  mcp pull     - Instalar modelo"
            echo "  mcp install  - Reinstalar sistema"
            echo "  mcp help     - Mostrar ayuda"
            ;;
    esac
}}

# Aliases de compatibilidad
alias mcp-server='mcp start'
alias mcp-models='mcp models'
"""
    
    return aliases

def update_bashrc():
    """Actualizar ~/.bashrc con aliases"""
    bashrc_path = Path.home() / ".bashrc"
    
    if bashrc_path.exists():
        content = bashrc_path.read_text()
        if "OLLAMA MCP SERVER" not in content:
            aliases = create_aliases()
            with open(bashrc_path, "a") as f:
                f.write(aliases)
            print("âœ… Aliases agregados a ~/.bashrc")
            print("ğŸ”„ Ejecuta: source ~/.bashrc")
        else:
            print("âœ… Aliases ya configurados en ~/.bashrc")
    else:
        print("âš ï¸ ~/.bashrc no encontrado")

def main():
    """FunciÃ³n principal de instalaciÃ³n"""
    print_header()
    
    # Verificar que estamos en el directorio correcto
    if not Path("ollama_mcp_server.py").exists():
        print("âŒ Error: Ejecuta este script desde el directorio del MCP Server")
        sys.exit(1)
    
    # Paso 1: Verificar Ollama
    if not check_ollama():
        print("âŒ Instala Ollama primero: https://ollama.ai/")
        sys.exit(1)
    
    # Paso 2: Configurar entorno virtual
    venv_path = setup_venv()
    
    # Paso 3: Instalar dependencias
    install_dependencies(venv_path)
    
    # Paso 4: Configurar .env
    setup_env_file()
    
    # Paso 5: Instalar modelos (opcional)
    install_choice = input("Â¿Instalar modelos recomendados? (y/N): ").strip().lower()
    if install_choice in ['y', 'yes', 'sÃ­', 's']:
        install_models()
    
    # Paso 6: Configurar aliases
    update_bashrc()
    
    # Resumen final
    print("\nğŸ‰" + "="*60 + "ğŸ‰")
    print("   Â¡INSTALACIÃ“N COMPLETADA!")
    print("ğŸ‰" + "="*60 + "ğŸ‰")
    print("\nğŸ“ PRÃ“XIMOS PASOS:")
    print("1. source ~/.bashrc")
    print("2. Edita .env con tu GitHub token")
    print("3. mcp start")
    print("\nğŸš€ Â¡Disfruta tu sistema de IA local!")

if __name__ == "__main__":
    main()
