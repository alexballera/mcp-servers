# ğŸ¤– Ollama MCP Server

Sistema integrado de IA para desarrollo con **Ollama local** + **GitHub** + **Model Context Protocol**.

Un agente de IA **completamente GRATIS**, **privado** y **sin lÃ­mites** para desarrollo de software.

> ğŸŒŸ **Nuevo**: Repositorio optimizado para instalaciÃ³n directa desde GitHub

## ğŸš€ InstalaciÃ³n RÃ¡pida desde GitHub

```bash
# 1. Clonar repositorio
git clone https://github.com/tu-usuario/mcp-servers.git
cd mcp-servers

# 2. Configurar entorno
python3 -m venv .venv
.venv/bin/pip install -r requirements.txt

# 3. Configurar GitHub token
cp .env.example .env
# Editar .env con tu GitHub token

# 4. Configurar terminal (opcional - ajustar ruta segÃºn tu instalaciÃ³n)
cat .bashrc.example >> ~/.bashrc
source ~/.bashrc

# 5. Instalar modelos de Ollama
ollama pull llama3.1:8b
ollama pull deepseek-coder:6.7b

# Â¡Listo!
python ollama_mcp_server.py  # Modo interactivo
# o usar comandos directos si configuraste .bashrc
```

## âœ¨ CaracterÃ­sticas Principales

- ğŸš€ **Ollama local**: Chat y asistencia de cÃ³digo sin lÃ­mites ni costos
- ğŸ“ **GitHub integration**: Buscar repos, analizar cÃ³digo, obtener archivos  
- ğŸ” **AnÃ¡lisis de cÃ³digo**: RevisiÃ³n y optimizaciÃ³n con IA especializada
- ğŸ’¬ **Modo dual**: Servidor interactivo Y comandos directos
- ğŸ”’ **Privado y seguro**: Todo funciona localmente
- âš¡ **Desde cualquier proyecto**: Usa el agente desde cualquier directorio

## ğŸ—ï¸ InstalaciÃ³n RÃ¡pida

### Requisitos Previos

- **Ollama** instalado: [https://ollama.ai/](https://ollama.ai/)
- **Python 3.8+**
- **Git**

### InstalaciÃ³n

```bash
# 1. Clonar y configurar
git clone <tu-repo> mcp-servers
cd mcp-servers

# 2. Configurar entorno
python3 -m venv .venv
.venv/bin/pip install requests python-dotenv PyGithub

# 3. Configurar GitHub token
cp .env.example .env
# Editar .env con tu GitHub token

# 4. Configurar terminal
cat .bashrc.example >> ~/.bashrc
source ~/.bashrc

# 5. Instalar modelos recomendados
ollama pull llama3.1:8b
ollama pull deepseek-coder:6.7b

# Â¡Listo!
mcp start
```

## ğŸ”§ ConfiguraciÃ³n de VS Code MCP

Para usar el servidor con VS Code y GitHub Copilot:

### 1. Instalar ExtensiÃ³n MCP
- Instala la extensiÃ³n "Model Context Protocol" en VS Code

### 2. Configurar settings.json
```json
{
  "mcp": {
    "servers": {
      "ollama-mcp": {
        "command": "python3",
        "args": [
          "/ruta/completa/a/mcp-servers/ollama_mcp_protocol.py"
        ],
        "cwd": "/ruta/completa/a/mcp-servers",
        "env": {
          "PATH": "/ruta/completa/a/mcp-servers/.venv/bin:${PATH}",
          "VIRTUAL_ENV": "/ruta/completa/a/mcp-servers/.venv"
        }
      }
    }
  }
}
```

### 3. Herramientas Disponibles
- `chat` - Chat general con Llama
- `code_assist` - Asistencia de cÃ³digo especializada  
- `github_search` - Buscar repositorios en GitHub
- `analyze_code` - AnÃ¡lisis de cÃ³digo con IA

**Importante:** AsegÃºrate de que tu `GITHUB_TOKEN` estÃ© en el archivo `.env`

## ğŸ¯ Modos de Uso

### ğŸ–¥ï¸ MODO 1: Servidor Interactivo

```bash
mcp start
# Te lleva a: ğŸ¤– MCP> donde escribes comandos interactivos
```

**Comandos disponibles en el servidor:**

```bash
ğŸ¤– MCP> help                    # Ver todos los comandos
ğŸ¤– MCP> chat Hola, Â¿cÃ³mo estÃ¡s? # Chat general con Llama
ğŸ¤– MCP> code Crear una API REST  # Asistencia de cÃ³digo con DeepSeek
ğŸ¤– MCP> github_search python ML # Buscar repositorios
ğŸ¤– MCP> github_repo microsoft/vscode # Info de repositorio
ğŸ¤– MCP> analyze_code <cÃ³digo>    # Analizar cÃ³digo
ğŸ¤– MCP> review_code <cÃ³digo>     # Revisar cÃ³digo
ğŸ¤– MCP> quit                    # Salir
```

### ğŸš€ MODO 2: Comandos Directos (Agente)

```bash
# Desde cualquier directorio/proyecto:
mcp chat "Â¿CÃ³mo optimizar este cÃ³digo Python?"
mcp code "Crear una API REST con FastAPI"
mcp github "machine learning python"

# Aliases mÃ¡s cortos:
ai-chat "explÃ­came async/await"
ai-code "mejores prÃ¡cticas Python"
ai-github "react hooks examples"

# AnÃ¡lisis de archivos:
analyze mi_script.py
review src/app.js
```

## ğŸ”§ ConfiguraciÃ³n

### GitHub Token (REQUERIDO)

1. Ve a [GitHub Settings > Developer settings > Personal access tokens](https://github.com/settings/tokens)
2. Genera token con permisos: `repo`, `public_repo`, `read:org`
3. Agrega a `.env`: `GITHUB_TOKEN=tu_token_aqui`

### Modelos Recomendados

```bash
# Modelos especializados (instalaciÃ³n automÃ¡tica con install.py)
ollama pull deepseek-coder:6.7b     # Mejor para cÃ³digo
ollama pull qwen2.5-coder:7b        # Alternativa rÃ¡pida
ollama pull llama3.2:3b             # Liviano y eficiente

# Ver modelos instalados
mcp models
```

## ğŸ“Š Comandos Disponibles

### Comandos de Sistema
```bash
mcp start       # Iniciar servidor interactivo
mcp status      # Estado del sistema
mcp models      # Ver modelos de Ollama
mcp pull <modelo> # Instalar nuevo modelo
mcp install     # Reinstalar/configurar
mcp help        # Ayuda completa
```

### Comandos de Agente (Directos)
```bash
mcp chat <mensaje>      # Chat con Llama
mcp code <consulta>     # Asistencia de cÃ³digo
mcp github <bÃºsqueda>   # Buscar en GitHub
analyze <archivo>       # Analizar cÃ³digo de archivo
review <archivo>        # Revisar cÃ³digo de archivo
```

## ğŸ’¡ Ejemplos PrÃ¡cticos

### Workflow TÃ­pico de Desarrollo
```bash
# 1. EstÃ¡s en tu proyecto
cd ~/mi-proyecto/

# 2. Buscar inspiraciÃ³n
mcp github "fastapi postgresql example"

# 3. Pedir ayuda con cÃ³digo
mcp code "CÃ³mo conectar FastAPI con PostgreSQL usando SQLAlchemy"

# 4. Analizar tu cÃ³digo
analyze src/main.py

# 5. Revisar antes del commit
review components/Header.jsx

# 6. Chat general
mcp chat "Â¿CuÃ¡les son las mejores prÃ¡cticas para APIs REST?"
```

### Casos de Uso EspecÃ­ficos
```bash
# Aprendizaje
mcp chat "ExplÃ­came el patrÃ³n Observer en JavaScript"
mcp code "Ejemplo de Factory Pattern en Python"

# Debugging
mcp code "Por quÃ© mi funciÃ³n async no funciona: <tu_cÃ³digo>"
analyze error.log

# InvestigaciÃ³n
mcp github "microservices kubernetes python"
mcp github "machine learning tensorflow examples"

# Code Review
review pull_request.diff
mcp code "Optimiza esta funciÃ³n: <funciÃ³n>"
```

## ğŸ—ï¸ Arquitectura del Sistema

```
mcp-servers/
â”œâ”€â”€ .env                    # ConfiguraciÃ³n (GitHub token, etc.)
â”œâ”€â”€ .env.example           # Plantilla de configuraciÃ³n
â”œâ”€â”€ .bashrc.example        # ConfiguraciÃ³n para ~/.bashrc
â”œâ”€â”€ .venv/                 # Entorno virtual Python
â”œâ”€â”€ requirements.txt       # Dependencias mÃ­nimas
â”œâ”€â”€ install.py            # Instalador automÃ¡tico
â”œâ”€â”€ ollama_mcp_server.py  # Servidor MCP interactivo
â”œâ”€â”€ mcp_direct.py         # Comandos directos/agente
â”œâ”€â”€ sync_bashrc.sh        # ğŸ”„ Auto-sync .bashrc â†’ .bashrc.example
â”œâ”€â”€ sync_bashrc.py        # ğŸ”„ Auto-sync (versiÃ³n Python)
â”œâ”€â”€ help.sh               # ğŸ“‹ Comandos de ayuda rÃ¡pida
â”œâ”€â”€ SYNC_SCRIPTS.md       # ğŸ“š DocumentaciÃ³n de sincronizaciÃ³n
â””â”€â”€ README.md             # Esta documentaciÃ³n
```

### Componentes Principales

1. **ollama_mcp_server.py**: Servidor interactivo principal
2. **mcp_direct.py**: Comandos directos para uso como agente
3. **install.py**: InstalaciÃ³n y configuraciÃ³n automÃ¡tica
4. **.bashrc.example**: ConfiguraciÃ³n de terminal optimizada
5. **sync_bashrc.sh/py**: Scripts de sincronizaciÃ³n automÃ¡tica

## ğŸ”„ Scripts de SincronizaciÃ³n

**MantÃ©n tu configuraciÃ³n sincronizada automÃ¡ticamente:**

```bash
# Ver estado de sincronizaciÃ³n
./sync_bashrc.sh --status

# SincronizaciÃ³n Ãºnica
./sync_bashrc.sh --once

# Monitoreo continuo (auto-sync cuando cambies ~/.bashrc)
./sync_bashrc.sh

# Ayuda rÃ¡pida
./help.sh
```

**CaracterÃ­sticas:**
- âœ… **Auto-detecciÃ³n** de cambios en `~/.bashrc`
- âœ… **Limpieza automÃ¡tica** de tokens y rutas especÃ­ficas
- âœ… **Git automation** - commit y push automÃ¡tico
- âœ… **Sin dependencias** (versiÃ³n Bash) o Python puro
- âœ… **DocumentaciÃ³n completa** en `SYNC_SCRIPTS.md`

## ğŸ”„ Flujo de Datos

```
Usuario â†’ Terminal â†’ .bashrc (funciÃ³n mcp) â†’ mcp_direct.py â†’ Ollama/GitHub API â†’ Respuesta
                  â†˜ ollama_mcp_server.py â†’ Servidor interactivo
```

## ğŸ› ï¸ Troubleshooting

### Ollama no responde
```bash
ollama serve              # Iniciar Ollama
ollama list              # Ver modelos instalados
mcp models               # Ver estado desde MCP
```

### Error de dependencias

```bash
cd mcp-servers
source .venv/bin/activate
pip install -r requirements.txt --upgrade
```

### GitHub no funciona
- Verificar token en `.env`
- Comprobar permisos del token
- `mcp status` para ver configuraciÃ³n

### Comandos no reconocidos
```bash
source ~/.bashrc         # Recargar configuraciÃ³n
mcp help                # Ver comandos disponibles
```

## ğŸ‰ Ventajas del Sistema

### vs ChatGPT/Claude
- âœ… **GRATIS**: Sin suscripciones ni lÃ­mites
- âœ… **Privado**: Tu cÃ³digo nunca sale de tu mÃ¡quina
- âœ… **Sin lÃ­mites**: Usa cuanto quieras
- âœ… **Especializado**: Modelos optimizados para cÃ³digo

### vs GitHub Copilot
- âœ… **MÃ¡s funciones**: Chat, bÃºsqueda, anÃ¡lisis completo
- âœ… **Sin dependencias**: No necesita IDE especÃ­fico
- âœ… **Flexible**: Modo interactivo Y comandos directos
- âœ… **Transparente**: Sabes exactamente quÃ© hace

### vs Otras Soluciones
- âœ… **Todo en uno**: IA + Git + AnÃ¡lisis + Chat
- âœ… **PortÃ¡til**: Funciona en cualquier mÃ¡quina
- âœ… **Customizable**: Agrega tus propios modelos/funciones
- âœ… **Sin vendor lock-in**: Es tuyo para siempre

## ğŸ“ˆ PrÃ³ximas Funciones

- [ ] IntegraciÃ³n con mÃ¡s Git providers
- [ ] AnÃ¡lisis de repositorios completos
- [ ] GeneraciÃ³n automÃ¡tica de documentaciÃ³n
- [ ] IntegraciÃ³n con bases de datos
- [ ] Workflow de CI/CD
- [ ] Soporte para mÃ¡s lenguajes

## ğŸ“„ Licencia

MIT License - Ãšsalo libremente para cualquier propÃ³sito.

---

**Â¡Tu asistente de IA local, gratis y sin lÃ­mites!** ğŸš€

Para soporte o contribuciones, abre un issue en el repositorio.
